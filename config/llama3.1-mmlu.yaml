model:
  model_type: "meta-llama/Llama-3.1-8B-Instruct"

dataset:
  name: "mmlu"
  train: "/scratch/dataset/mmlu/data/"
  test: "/scratch/dataset/mmlu/data/test/"
  cot: "/scratch/dataset/mmlu/data/dev/"
  nshot: 5
  split: "test"

save:
  run_dir: "save/llama3.1-8B_mmlu/"
  logger: "inference.log"

eval:
  cot: True
  max_gen_toks: 256

quantization:
  wbit: 8
  abit: 8
  num_samples: 512
  wqtype: smooth_quant
  xqtype: smooth_quant_token

train:
  batch_size: 512

smooth:
  alpha: 0.85

t2c:
  swl: 32
  sfl: 26

export:
  export_samples: 0