seed: 5000

model:
  model_type: "meta-llama/Llama-3.2-3B-Instruct"

dataset:
  name: "wikitext"
  path: "wikitext-2-raw-v1"
  split: "test"

save:
  run_dir: "save/Llama-3.2-3b-wikitext/"
  logger: "inference.log"

eval:
  chunk_size: 2048
  n_samples: 16

quantization:
  wbit: 8
  abit: 8
  num_samples: 2048
  wqtype: smooth_quant
  xqtype: smooth_quant_token
  rescale_out: True

train:
  batch_size: 2048

smooth:
  alpha: 0.85
  flag: False

t2c:
  swl: 32
  sfl: 26

export:
  export_samples: 0