model:
  model_type: "meta-llama/Llama-3.2-3B-Instruct"

dataset:
  name: "gsm8k"
  train: "/share/seo/llm_datasets/gsm8k/train.jsonl"
  test: "/share/seo/llm_datasets/gsm8k/gsm8k_test.jsonl"
  split: "test"

save:
  run_dir: "save/llama3.2-3B_gsm8k/"
  logger: "inference.log"

eval:
  cot: True
  max_gen_toks: 256

quantization:
  wbit: 8
  abit: 8
  num_samples: 512
  wqtype: smooth_quant
  xqtype: smooth_quant_token

train:
  batch_size: 512

smooth:
  alpha: 0.85

t2c:
  swl: 32
  sfl: 26

export:
  export_samples: 0